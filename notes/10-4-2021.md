# NeRFactor Output (October 4, 2021)
## NeRFactor Process Flow Chart
![](nerfactor-diagram.png "NeRFactor Flow")

## NeRFactor Execution Progress
- [x] 0. Data Preprocessing
- [x] 1. BRDF Prior
- [x] 2. NeRF (with input image)
- [x] 3. Geometry Buffers (optimize normal & visibility MLPs) (this takes 3+ days usually)
- [ ] 4. Joint Optimization (running...)
    * Albedo & BRDF Identity MLP and light trained from scratch
    * Optimize along with normal and visibility from #3

## 0. Data Preprocessing
### BRDF Dataset Conversion
Dataset converted into NeRFactor format stored in `cplvm1` remote server: `/home/jiwonchoi/data/brdf_merl_npz/ims512_envmaph16_spp1/`

### Pinecone Real Capture Conversion
Stored in `cpvm1` remote server: `/home/jiwonchoi/data/nerf_real_360_proc/pinecone/`

## 1. BRDF Prior
* Final checkpoint (50th) stored in remote server: `/home/jiwonchoi/output/train/merl/lr1e-2/vis_test/`
* Checkpoint Visualization
  * In NeRFactor paper, "we seek to learn latent space of real world BRDFs with this specular prior training". They seem to train this to tackle specular objects. The output video changes the object with different specularity.

[[Video Output]](../nerfactor_output/brdf_prior/ckpt-50.mp4)
https://user-images.githubusercontent.com/25876799/136686841-0200b2b8-87d8-47b6-934d-05dcfcf984a5.mp4

## 2. Plain NeRF
![](../nerfactor_output/nerf_pinecone/ckpt-20.mp4)

