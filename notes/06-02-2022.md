# Neural Rendering Updates (June 2, 2022)

## Test Camera Parameters
Tested multiple combinations of:
1. exposure time/shutter speed
2. iso
3. Aperture

Acceptable Combinations ([view samples](https://drive.google.com/drive/folders/141S0thelgdAKWtmcB0OsL4_SAqthkxaG?usp=sharing)):

| Exposure Time | ISO | Aperture (f number) |
| --- | --- | --- |
| 1/30 | 100 | f13 |
| 1/30 | 200 | f13 |
| 1/30 | 200 | f16 |

* `iso=400` was too bright and overexposed
* Aperture `f8` wasnâ€™t able to capture the depth and the details of hologram
* Other Reference: [Canon Play](http://www.canonoutsideofauto.ca/play/) to test out these parameters

<hr>

## Rendering Trajectory
Have 2 proposed solutions:
1. Try to modify NeRF's view matrix (so far failed)
2. Crop rendered image --> Produce Video

### 1. Modify View Matrix
How view matrix is constructed in NeRF:
```
camera_coordinate = (x, y, z)
up = (0, 0, -1) <--random constant value according to the author

cam_normalized = normalize(camera_coordinate)
right_vec = cam_normalized X up <--cross product
up_vec = cam_normalized X right_vec <--cross product

matrix:
| right_x  up_x  cam_normalized_x  camera_coordinate_x |
| right_y  up_y  cam_normalized_y  camera_coordinate_y |
| right_z  up_z  cam_normalized_z  camera_coordinate_z |
|   0       0           0                    1
```
Rotation of camera origin does not rotate its viewing direction, but rotates camera itself.

Something like the following is required:
```
lookAt(M, eye_x, eye_y, eye_z, center_x, center_y, center_z, up_dx, up_dy, up_dz)
```
where `center_*` and `up_*` params are fixed, while we should be able to change `eye_*` to change its view points.

### 2. Crop rendered image --> Produce Video
1. Capture images with the aruco markers
2. Apply homography with aruco markers, to the NeRF rendered images
3. Crop rendered frames/images based on the aruco markers' pixel location
4. Synthesize the images and produce the rendered output

<hr>

## TODO
- Train NeRF model without calibration